{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8226df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from transformers.models.bert.modeling_bert import BertModel\n",
    "from transformers.models.bert.tokenization_bert import BertTokenizer\n",
    "from typing import AnyStr, List, Tuple\n",
    "from transformers import PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e70eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')  \n",
    "# if gpu is available in your computer, conduct your model on gpu(i.e., cuda); otherwise, the model is conducted on cpu device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cdeafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"../bert_cn/\")\n",
    "bert_model = BertModel.from_pretrained('../bert_cn/').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f9845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = bert_model.config.hidden_size\n",
    "classifier = nn.Sequential(nn.Linear(hidden_size, 2*hidden_size), \n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(2*hidden_size, 2)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f33ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    with open(fname, 'r') as fr:\n",
    "        doc = fr.read()\n",
    "    sent_list = doc.replace('\\n', '').replace(' ', '').split('ã€‚')\n",
    "    return [sent for sent in sent_list if len(sent) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337157e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_batch_transformer(text: List, tokenizer: PreTrainedTokenizer, text_pair: List = None):\n",
    "    \"\"\"Turn a piece of text into a batch for transformer model\n",
    "\n",
    "    :param text: The text to tokenize and encode\n",
    "    :param tokenizer: The tokenizer to use\n",
    "    :param: text_pair: An optional second string (for multiple sentence sequences)\n",
    "    :return: A list of IDs and a mask\n",
    "    \"\"\"\n",
    "    max_len = tokenizer.max_len if hasattr(tokenizer, 'max_len') else tokenizer.model_max_length\n",
    "    if text_pair is None:\n",
    "        items = [tokenizer.encode_plus(sent, text_pair=None, add_special_tokens=True, max_length=max_len,\n",
    "                                       return_length=False, return_attention_mask=True,\n",
    "                                       return_token_type_ids=True)\n",
    "                 for sent in text]\n",
    "    else:\n",
    "        assert len(text) == len(text_pair)\n",
    "        items = [tokenizer.encode_plus(s1, text_pair=s2, add_special_tokens=True, max_length=max_len,\n",
    "                                        return_length=False, return_attention_mask=True,\n",
    "                                            return_token_type_ids=True)\n",
    "                                        for s1, s2 in zip(text, text_pair)]\n",
    "    return [item['input_ids'] for item in items], \\\n",
    "              [item['attention_mask'] for item in items], \\\n",
    "                 [item['token_type_ids'] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3639ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_with_device(device):\n",
    "    def collate_batch_transformer(doc: Tuple):\n",
    "        input_ids = doc[0]\n",
    "        masks = doc[1]\n",
    "        seg_ids = doc[2]\n",
    "        \n",
    "        max_length = max([len(i) for i in input_ids])\n",
    "        input_ids = [(i + [0] * (max_length - len(i))) for i in input_ids]\n",
    "        masks = [(m + [0] * (max_length - len(m))) for m in masks]\n",
    "        seg_ids = [(s + [0] * (max_length - len(s))) for s in seg_ids]\n",
    "\n",
    "        assert (all(len(i) == max_length for i in input_ids))\n",
    "        assert (all(len(m) == max_length for m in masks))\n",
    "        assert (all(len(s) == max_length for s in seg_ids))\n",
    "        return torch.tensor(input_ids, device=device), torch.tensor(masks, device=device), \\\n",
    "                    torch.tensor(seg_ids, device=device)\n",
    "    return collate_batch_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "492d725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocModel(nn.Module):\n",
    "    def __init__(self, model, classifier, tokenizer, device):\n",
    "        super(DocModel, self).__init__()\n",
    "        self.model =  model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.classifier = classifier\n",
    "        self.collate_fn = collate_batch_with_device(device)\n",
    "    \n",
    "    def obtain_optim(self, learning_rate=None):\n",
    "        def lr_coefficient(par_name):\n",
    "        # layer-wise fine-tuning\n",
    "            if \"layer.\" in par_name:\n",
    "                layer_num = int(par_name.split(\"layer.\")[1].split(\".\", 1)[0])\n",
    "                return pow(0.8, 12 - layer_num)\n",
    "            elif \"embedding\" in par_name:\n",
    "                return pow(0.8, 13)\n",
    "            else:\n",
    "                return 1.0\n",
    "        if learning_rate is None:\n",
    "            learning_rate = self.learning_rate\n",
    "        optimizerGroupedParameters = [{'params': p, 'lr': learning_rate * lr_coefficient(n)}\n",
    "                                        for n, p in self.named_parameters()]\n",
    "        return torch.optim.Adam(optimizerGroupedParameters)\n",
    "    \n",
    "    def pred(self, passage, temperature=1.0):\n",
    "        rst = text_to_batch_transformer(passage, self.tokenizer)\n",
    "        input_ids, masks, _ = self.collate_fn(rst)\n",
    "        bert_dict = self.model(input_ids=input_ids, attention_mask=masks)\n",
    "        logits = self.classifier(\n",
    "            bert_dict.pooler_output.max(dim=0)[0]\n",
    "        )\n",
    "        logits = F.softmax(logits / temperature, dim=-1)\n",
    "        return logits\n",
    "    \n",
    "    def lossAndAcc(self, passage, label):\n",
    "        logits =  self.pred(passage_list)\n",
    "        loss = logits[label].log().neg() # cross entropy\n",
    "        return loss, logits.data.argmax()==label\n",
    "        \n",
    "    def training(self, train_set, val_set, batch_size=32, learning_rate=5e-5):\n",
    "        optim = self.obtain_optim(learning_rate)\n",
    "        tr_idxs = random.sample(range(len(train_set)), len(train_set))\n",
    "        true_pred_cnt = 0\n",
    "        loss_list = []\n",
    "        for step, idx in enumerate(tr_idxs):\n",
    "            loss, tp = self.lossAndAcc(train_set[0][idx], train_set[1][idx])\n",
    "            true_pred_cnt += float(tp)\n",
    "            loss.backward()\n",
    "            loss_list.append(loss.data.item())\n",
    "            if len(loss_list)>100:\n",
    "                loss_list.pop(0)\n",
    "                \n",
    "            if ((step+1)%batch_size)==0:\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "                print(f\"loss/acc = {np.mean(loss_list)}/{true_pred_cnt/float(batch_size)}\")\n",
    "                true_pred_cnt = 0\n",
    "        self.valid(val_set, torch.tensor(val_set[1]), 'validation')\n",
    "        \n",
    "    def pred_Logits(self, data, idxs=None, batch_size=20):\n",
    "        preds = []\n",
    "        if idxs is None:\n",
    "            idxs = list(range(len(data[0])))\n",
    "        if not hasattr(self, 'collate_fn'):\n",
    "            collate_fn = data.collate_raw_batch\n",
    "        else:\n",
    "            collate_fn = self.collate_fn\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in trange(0, len(idxs), 1):\n",
    "                doc = data[0][idxs[i]]\n",
    "                pred, _ = self.pred(doc)\n",
    "                preds.append(pred)\n",
    "        print(len(preds))\n",
    "        pred_tensor = torch.stack(preds)\n",
    "        print(\"pred_tensor.shape:\", pred_tensor.shape)\n",
    "        return pred_tensor\n",
    "    \n",
    "    def prediction(self, data, idxs=None, batch_size=20):\n",
    "        pred_tensor = self.pred_Logits(data, idxs, batch_size)\n",
    "        vals, idxs = pred_tensor.sort(dim=1)\n",
    "        return idxs[:, -1], vals[:, -1]\n",
    "\n",
    "    def acc_P_R_F1(self, y_true, y_pred):\n",
    "        return accuracy_score(y_true, y_pred.cpu()), \\\n",
    "               precision_recall_fscore_support(y_true, y_pred.cpu())\n",
    "\n",
    "    def Perf(self, data, label, idxs=None, batch_size=20):\n",
    "        y_pred, _ = self.prediction(data, idxs=idxs, batch_size=batch_size)\n",
    "        y_true = label[idxs] if idxs is not None else label\n",
    "        return self.acc_P_R_F1(y_true, y_pred)\n",
    "\n",
    "    def valid(self, test_set, test_label, test_suffix, step=0):\n",
    "        test_label = test_label.argmax(dim=1) if test_label.dim() > 1 else test_label\n",
    "        rst_model = self.Perf(test_set, test_label)\n",
    "        print(\"test_label : \", test_label.tolist())\n",
    "        acc_v, (p_v, r_v, f1_v, _) = rst_model\n",
    "        print(\"BestPerf : \", rst_model)\n",
    "#         class_num = len(p_v)\n",
    "#         output_items = [(\"valid_acc\", acc_v)] + \\\n",
    "#                        [('valid_prec_{}'.format(i), p_v[i]) for i in range(class_num)] + \\\n",
    "#                        [('valid_recall_{}'.format(i), r_v[i]) for i in range(class_num)] + \\\n",
    "#                        [('valid_f1_{}'.format(i), f1_v[i]) for i in range(class_num)]\n",
    "#         fitlog.add_metric({f\"{test_suffix}\": dict(output_items)}, step=step)\n",
    "#         fitlog.add_best_metric({f\"FinalPerf_{test_suffix}\": dict(output_items)})\n",
    "        return acc_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3eee201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a76a83a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dir = './positive_dir/'\n",
    "pos_docs = [read_file(f\"{d_dir}/{fname}\") for fname in os.listdir(d_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bb89ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_labels = [1]*len(pos_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb95e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_set = (pos_docs, pos_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8c04272",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_b = DocModel(bert_model, classifier, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d69d3e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "pred_tensor.shape: torch.Size([20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30046/610110457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_30046/2674090498.py\u001b[0m in \u001b[0;36mvalid\u001b[0;34m(self, test_set, test_label, test_suffix, step)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_suffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mrst_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPerf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_label : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0macc_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrst_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30046/2674090498.py\u001b[0m in \u001b[0;36mPerf\u001b[0;34m(self, data, label, idxs, batch_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mPerf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0midxs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_P_R_F1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30046/2674090498.py\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(self, data, idxs, batch_size)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mpred_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_Logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "d_b.valid(pos_set, torch.tensor(pos_set[1]), 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afd39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
